{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_tweets_full_2.csv',header=(0))\n",
    "train.dropna()\n",
    "X = list(train[\"tweets\"])\n",
    "y = list(train[\"maj_label\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def print_report(pipe):\n",
    "    y_actuals = y_test\n",
    "    y_preds = pipe.predict(X_test)\n",
    "    report = metrics.classification_report(y_actuals, y_preds)\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_actuals, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emma\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.2 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Emma\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.21.2 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Emma\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Emma\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.2 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Emma\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.2 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  derogatory       0.88      0.52      0.66      1470\n",
      "      normal       0.77      0.99      0.87      7737\n",
      "        spam       1.00      0.02      0.04      1654\n",
      "\n",
      "    accuracy                           0.78     10861\n",
      "   macro avg       0.88      0.51      0.52     10861\n",
      "weighted avg       0.82      0.78      0.71     10861\n",
      "\n",
      "accuracy: 0.779\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load('model_LR2.pkl')\n",
    "print_report(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag: derogatory\n",
      "Most Positive Coefficients:\n",
      "[('idiot', 8.384144029045096), ('idiots', 7.16733446491027), ('fucking', 6.952766004423737), ('rt', 6.90935999053271), ('bad', 4.40000746260379), ('retarded', 4.271009053181252), ('ass', 4.067765785243252), ('fucked', 3.7938526342865186), ('hell', 3.7100983874893148), ('damn', 3.574748098582929)]\n",
      "Most Negative Coefficients:\n",
      "[('good', -1.6700954791900573), ('new', -1.377742164297901), ('mean', -1.32774905547556), ('enough', -1.2710794438477495), ('late', -1.2022169775036722), ('co', -1.1872949976325533), ('down', -1.174563897019097), ('only', -1.1672710682580456), ('road', -1.1558058122352879), ('own', -1.1461722699491044)]\n",
      "--------------------------------------\n",
      "Tag: normal\n",
      "Most Positive Coefficients:\n",
      "[('characters', 1.2098778652217332), ('nice', 1.2097139247327509), ('100', 1.1986169771008859), ('happen', 1.123610239969527), ('thoughts', 1.0906178241629014), ('ai', 1.0535383645544178), ('premium', 1.0434694620165041), ('player', 1.0303426284343065), ('written', 1.02465912125295), ('insights', 1.0122928733781702)]\n",
      "Most Negative Coefficients:\n",
      "[('idiot', -5.021978941108894), ('idiots', -4.402781284707639), ('fucking', -3.6349409353076143), ('rt', -3.2118688602201244), ('retarded', -3.2029421093135904), ('bad', -2.588211081001234), ('fucked', -2.4714312746720863), ('hate', -2.360340760815325), ('ugly', -2.280687186187267), ('hell', -2.119065862543644)]\n",
      "--------------------------------------\n",
      "Tag: spam\n",
      "Most Positive Coefficients:\n",
      "[('surely', 1.3679619181897054), ('mean', 1.2209766228172254), ('received', 1.1488485508966753), ('enough', 1.1385585513900427), ('company', 1.1256010376702799), ('top', 1.0898511905043096), ('anthony', 1.0690194589175743), ('petition', 1.0527551920637155), ('silicone', 1.0379225012428495), ('kylie', 1.008888808331938)]\n",
      "Most Negative Coefficients:\n",
      "[('rt', -3.697491130312719), ('idiot', -3.3621650879362392), ('fucking', -3.317825069115983), ('idiots', -2.7645531802026926), ('damn', -2.0975089339922417), ('ass', -1.959037955588789), ('bad', -1.8117963816025064), ('fuck', -1.6180192366248305), ('hell', -1.5910325249456747), ('bitch', -1.517352139799081)]\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get overall weights\n",
    "vec = model.steps[0][1]\n",
    "clf = model.steps[2][1]\n",
    "for i, tag in enumerate(clf.classes_):\n",
    "    coefficients = clf.coef_[i]\n",
    "    weights = list(zip(vec.get_feature_names(),coefficients))\n",
    "    print('Tag:',tag)\n",
    "    print('Most Positive Coefficients:')\n",
    "    print(sorted(weights,key=lambda x: -x[1])[:10])\n",
    "    print('Most Negative Coefficients:')\n",
    "    print(sorted(weights,key=lambda x: x[1])[:10])\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAH - Domestico to International flight - I forgot to say, both flights are with United. https://t.co/md2c7Akwfk\n",
      "*\n",
      "Tag: derogatory\n",
      "    forgot, -0.16791344370801273\n",
      "    flight, -0.3170312719761709\n",
      "    with, -0.2577867526046609\n",
      "    to, -0.6043078524476211\n",
      "    both, -0.04463652152194795\n",
      "    are, 0.4316134478454083\n",
      "    flights, 0.2591054852021373\n",
      "  overall weight: -0.7009569092108678\n",
      "Tag: normal\n",
      "    forgot, 0.04226449110022955\n",
      "    flight, -0.44716547791401795\n",
      "    with, -0.21921179098080978\n",
      "    to, 0.2953410223317563\n",
      "    both, -0.2951991403242208\n",
      "    are, -0.33236651798375993\n",
      "    flights, -0.5554873792742393\n",
      "  overall weight: -1.511824793045062\n",
      "Tag: spam\n",
      "    forgot, 0.1256489526077836\n",
      "    flight, 0.7641967498901909\n",
      "    with, 0.4769985435854655\n",
      "    to, 0.3089668301158796\n",
      "    both, 0.339835661846169\n",
      "    are, -0.0992469298616439\n",
      "    flights, 0.29638189407210286\n",
      "  overall weight: 2.2127817022559477\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "# get weights for individual examples\n",
    "\n",
    "y_preds = model.predict(X)\n",
    "train['predicted_label'] = y_preds\n",
    "\n",
    "def get_weight_one_sample(words):\n",
    "    for i, tag in enumerate(clf.classes_):\n",
    "        pad = \"    \"\n",
    "        coefficients = clf.coef_[i]\n",
    "        weights = list(zip(vec.get_feature_names(),coefficients))\n",
    "        print('Tag:',tag)\n",
    "        weights_sorted = sorted(weights,key=lambda x: -x[1])\n",
    "        weights_sorted = dict(weights_sorted)\n",
    "        overall_weight = 0\n",
    "        for i in words:\n",
    "            val = weights_sorted.get(i,0)\n",
    "            if val is not 0:\n",
    "                print(pad + str(i) + ', ' + str(val))\n",
    "            overall_weight = overall_weight + val\n",
    "        pad = \"  \"\n",
    "        print(pad + \"overall weight: \" + str(overall_weight))\n",
    "    print('*')\n",
    "\n",
    "# spam\n",
    "idx = 5089\n",
    "tweet = X[idx]\n",
    "label = y[idx]\n",
    "print(tweet)\n",
    "#print(label)\n",
    "#print(y_preds[idx])\n",
    "print('*')\n",
    "get_weight_one_sample(set(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's always the filthy bitch that comes in the picture.. ü§¶üèΩ‚Äç‚ôÇÔ∏è\n",
      "derogatory\n",
      "Tag: derogatory\n",
      "    bitch, 3.01906509545287\n",
      "    comes, 0.05109874550810478\n",
      "    that, -0.006718444559540498\n",
      "    always, 0.11040574296039389\n",
      "    in, -0.6608141716450816\n",
      "    filthy, 1.632728222328763\n",
      "    the, -0.008964799218398491\n",
      "  overall weight: 4.13680039082711\n",
      "Tag: normal\n",
      "    bitch, -1.5017129556538038\n",
      "    comes, -0.1380461187258348\n",
      "    that, -0.20459392079932168\n",
      "    always, 0.3497067652373991\n",
      "    in, 0.4283272847299151\n",
      "    filthy, -1.309619791495735\n",
      "    the, 0.07404841429734252\n",
      "  overall weight: -2.3018903224100384\n",
      "Tag: spam\n",
      "    bitch, -1.517352139799081\n",
      "    comes, 0.08694737321773033\n",
      "    that, 0.2113123653588483\n",
      "    always, -0.46011250819779775\n",
      "    in, 0.23248688691514086\n",
      "    filthy, -0.32310843083302915\n",
      "    the, -0.06508361507895734\n",
      "  overall weight: -1.8349100684171458\n",
      "*\n",
      "one person followed me and one person unfollowed me // automatically checked by https://t.co/J66pWkCLxT\n",
      "normal\n",
      "Tag: derogatory\n",
      "    me, 0.5184832669230083\n",
      "    checked, -0.8002896581383917\n",
      "    automatically, 0.029885374381361043\n",
      "    by, 0.08153135924730656\n",
      "    one, -0.5621578605507224\n",
      "    person, 0.20077243536044792\n",
      "    unfollowed, 0.022803611740324\n",
      "    followed, 0.6936483229988282\n",
      "    and, -0.5317079370208324\n",
      "  overall weight: -0.34703108505867053\n",
      "Tag: normal\n",
      "    me, -0.41307446799748465\n",
      "    checked, 0.8548905864800753\n",
      "    automatically, -0.24637994215347908\n",
      "    by, 0.13650346274646294\n",
      "    one, 0.5236350803397651\n",
      "    person, -0.013707481411081667\n",
      "    unfollowed, 0.27511644053138856\n",
      "    followed, -0.3193146243576802\n",
      "    and, 0.39287867991888814\n",
      "  overall weight: 1.1905477340968544\n",
      "Tag: spam\n",
      "    me, -0.1054087989255164\n",
      "    checked, -0.054600928341681294\n",
      "    automatically, 0.2164945677721186\n",
      "    by, -0.2180348219937728\n",
      "    one, 0.03852278021096904\n",
      "    person, -0.1870649539493656\n",
      "    unfollowed, -0.29792005227171275\n",
      "    followed, -0.37433369864114724\n",
      "    and, 0.13882925710197272\n",
      "  overall weight: -0.8435166490381358\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "# derogatory\n",
    "idx = 108#14\n",
    "tweet = X[idx]\n",
    "label = y[idx]\n",
    "print(tweet)\n",
    "print(label)\n",
    "get_weight_one_sample(set(tweet.split()))\n",
    "# normal\n",
    "idx = 54270\n",
    "tweet = X[idx]\n",
    "label = y[idx]\n",
    "print(tweet)\n",
    "print(label)\n",
    "get_weight_one_sample(set(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 tweet_id maj_label  \\\n",
      "1339   849770809681956864      spam   \n",
      "4990   848926336890662914      spam   \n",
      "5089   847877626698092545      spam   \n",
      "5439   850468238525964288      spam   \n",
      "5484   847467465697239044      spam   \n",
      "5539   849488700786573312      spam   \n",
      "5625   850703639656247300      spam   \n",
      "5956   849924774205771778      spam   \n",
      "6265   848996843149287427      spam   \n",
      "6723   848154865973047296      spam   \n",
      "6922   850455139752325120      spam   \n",
      "7066   849141735376785409      spam   \n",
      "7450   847403544479096833      spam   \n",
      "8833   849551032338272256      spam   \n",
      "9122   849799918134886400      spam   \n",
      "9521   850153506354978816      spam   \n",
      "9914   848792286930620416      spam   \n",
      "10202  849564261181517827      spam   \n",
      "10727  849027507709980675      spam   \n",
      "11006  848881705289166848      spam   \n",
      "11019  849907380397768704      spam   \n",
      "11071  849696054589239297      spam   \n",
      "11161  848148167682076672      spam   \n",
      "11445  847542921238900736      spam   \n",
      "11547  850732546824577025      spam   \n",
      "11562  850065425983569920      spam   \n",
      "11804  847956597032792064      spam   \n",
      "12060  847393876637659141      spam   \n",
      "12271  850377150838571008      spam   \n",
      "12565  847472515626684416      spam   \n",
      "...                   ...       ...   \n",
      "45546  848594672318656514      spam   \n",
      "46185  847964645906415617      spam   \n",
      "46327  850017980012523522      spam   \n",
      "46806  849994617739018240      spam   \n",
      "47022  850351704017076224      spam   \n",
      "47225  848880153425887232      spam   \n",
      "47245  848940954065272833      spam   \n",
      "47790  847537607038914560      spam   \n",
      "47846  847615969232957440      spam   \n",
      "48133  850732571990392834      spam   \n",
      "48312  849313399846686721      spam   \n",
      "48389  850033247291666433      spam   \n",
      "48919  850199433991999490      spam   \n",
      "49474  847758411957542912      spam   \n",
      "49731  847667487873220609      spam   \n",
      "49999  847811641894981632      spam   \n",
      "50109  848761282652061696      spam   \n",
      "50112  847457336461369345      spam   \n",
      "50155  850154257143803904      spam   \n",
      "50300  849440449504956417      spam   \n",
      "50745  848374563624898560      spam   \n",
      "51089  850175077647663104      spam   \n",
      "51597  848988530042957824      spam   \n",
      "51903  848490305422839808      spam   \n",
      "52312  847861562496778240      spam   \n",
      "52626  848062759052992512      spam   \n",
      "52778  850067229513314308      spam   \n",
      "53160  850798636447318016      spam   \n",
      "53404  849194440988270592      spam   \n",
      "53583  847730842810044416      spam   \n",
      "\n",
      "                                                  tweets predicted_label  \n",
      "1339   @BakeyFilms @gormanseamus YESSSSSSSSSSS!!!!!!!...            spam  \n",
      "4990   NEW TO MARKET!! Spacious 2/2, 1900sqft under a...            spam  \n",
      "5089   IAH - Domestico to International flight - I fo...            spam  \n",
      "5439   Carter Page -- A Former Trump Adviser Met With...            spam  \n",
      "5484   #NewMusic @Gospel_Haven\\n Check out #Beautiful...            spam  \n",
      "5539   #GzEnter10ment: [{{{https://t.co/eXZz9STBmw}}}...            spam  \n",
      "5625   @bhartijainTOI Is it true that Arvind Kejriwal...            spam  \n",
      "5956   If curling up with a good book could be made m...            spam  \n",
      "6265   Apr 3 1917‚ÄîPARIS PUTS OUR FLAG WITH THOSE OF A...            spam  \n",
      "6723   Men will be flying private jet like is Uber \"0...            spam  \n",
      "6922   end the IRS (keep our money), make our food go...            spam  \n",
      "7066   https://t.co/IGGUSsI0tc Just received my car i...            spam  \n",
      "7450   #TheWalkingDead I so did not see that coming. ...            spam  \n",
      "8833   We lost the funniest man who ever lived today ...            spam  \n",
      "9122   Hi @OttLegalRebels! Whenever in Northern Italy...            spam  \n",
      "9521   #SmartDubai launches #DubaiCareers, a smart &a...            spam  \n",
      "9914   I've barely been drinking lately. (Who am I, r...            spam  \n",
      "10202  Death Mask / Stay Rad tees flying out! Overwhe...            spam  \n",
      "10727  Looking for way to slow down and embrace a sim...            spam  \n",
      "11006  Drinking a Warrah by @platformbeers @ Clevelan...            spam  \n",
      "11019  @QueenTME @unitedweare23 Victims??? What world...            spam  \n",
      "11071  i mean....if you're going to scold a vegan abo...            spam  \n",
      "11161  Full Gallery: https://t.co/ZwNxA8xaj7\\nStunnin...            spam  \n",
      "11445  Favourite Dustin Johnson may be out of the Mas...            spam  \n",
      "11547  #RedWings 2013/14 TOTALLY CERTIFIED NIKLAS KRO...            spam  \n",
      "11562  Stoke City v Liverpool Betting: Visitors could...            spam  \n",
      "11804  International Sales Engineer - Redhill, Surrey...            spam  \n",
      "12060  Origi has an astonishing goal scoring record f...            spam  \n",
      "12271  Our firm gives this advice for any type of acc...            spam  \n",
      "12565  Found a Transponder Snail! \\nShots of those Sp...            spam  \n",
      "...                                                  ...             ...  \n",
      "45546  \"These books are PACKED with action.\" GETTING ...            spam  \n",
      "46185  @hm_thackston oh well ü§∑üèª‚Äç‚ôÄÔ∏è we're all differen...            spam  \n",
      "46327  NYC set to adopt long-debated changes to stude...            spam  \n",
      "46806  Like I didn't know men like this lived in my s...            spam  \n",
      "47022  #NOWPLAYING Drake @drake - One Dance ON https:...            spam  \n",
      "47225  Northern lights, Norway. Definitely a bucket-l...            spam  \n",
      "47245  @TheJesuitPost @hunter_chomsky that maybe true...            spam  \n",
      "47790  Paris Jackson 'incredibly offended' by Joseph ...            spam  \n",
      "47846  @187TuMadre @SWOSullivan @kaostwist That impli...            spam  \n",
      "48133  Exactly!!!!!!!! I was like Wtf ü§¶üèæ‚Äç‚ôÄÔ∏èü§¶üèæ‚Äç‚ôÄÔ∏èü§¶üèæ‚Äç‚ôÄÔ∏è...            spam  \n",
      "48312  always remind myself nothing product about ins...            spam  \n",
      "48389  @Megan94Bieber Oh no! Please send us a DM with...            spam  \n",
      "48919  @TRobinsonNewEra @pazzalou THE NORDIC NATIONS ...            spam  \n",
      "49474  Retweeted Ron B (@ClubSpeaks):\\n\\n@FoxNews @je...            spam  \n",
      "49731  JOB AVAILABLE: Chief Executive Officer\\nTHE CO...            spam  \n",
      "49999  @VP @marthamaccallum Love you, Vice President,...            spam  \n",
      "50109  Guaranteed Host @OnraHost offers unmatched tec...            spam  \n",
      "50112  @maryannemercog Factcheck, Politifact, Snopes ...            spam  \n",
      "50155  He did not let any grass grow under his feet t...            spam  \n",
      "50300  Lost books, some one took petrol from bike, lo...            spam  \n",
      "50745  @rachelandrew But clearly you wanted anything ...            spam  \n",
      "51089  Zcash Enters Top 10 Cryptocurrencies By Market...            spam  \n",
      "51597  Audi A7 S7 4G 2010-2014y Tail Lights LED Rear ...            spam  \n",
      "51903  ~ Highly Ornate Cast Iron Antique French Wood ...            spam  \n",
      "52312  For 1 Glorietta stub, tweet us the name of @Th...            spam  \n",
      "52626  Jeanine Pirro Rips Liberals: ‚ÄòBozos‚Äô Still Hav...            spam  \n",
      "52778  ‚ô†‚àû Cushions in Vibrant Designs. Good selection...            spam  \n",
      "53160  On This Day: Liverpool 3 Manchester United 3 -...            spam  \n",
      "53404  Then this bus screeches up, stops next to me, ...            spam  \n",
      "53583  White Topaz Engagement Ring &amp; Diamonds Pea...            spam  \n",
      "\n",
      "[147 rows x 4 columns]\n",
      "                 tweet_id   maj_label  \\\n",
      "2      850010509969465344      normal   \n",
      "3      850433664890544128  derogatory   \n",
      "15     850660404770590720      normal   \n",
      "21     848926030723031040      normal   \n",
      "23     848975292794318848      normal   \n",
      "34     849966683662032896  derogatory   \n",
      "46     848338236770582529      normal   \n",
      "75     849711858751868936  derogatory   \n",
      "76     847760077108822016      normal   \n",
      "79     848573151328043011      normal   \n",
      "83     849115860715413504  derogatory   \n",
      "93     849426637657710592      normal   \n",
      "98     848594131257577473  derogatory   \n",
      "105    849091848337489920      normal   \n",
      "114    850392854304346113  derogatory   \n",
      "121    849191429494546434      normal   \n",
      "124    849995901200355328      normal   \n",
      "128    850570969634754560      normal   \n",
      "141    850179691386249217  derogatory   \n",
      "142    849588915279364096      normal   \n",
      "143    847652971361869825  derogatory   \n",
      "153    849659786463334401  derogatory   \n",
      "174    850761437156962304  derogatory   \n",
      "180    850445232789487616  derogatory   \n",
      "181    849350649473114113      normal   \n",
      "183    850194514073366530  derogatory   \n",
      "191    850452866422755328      normal   \n",
      "193    848678877174149120  derogatory   \n",
      "197    849093450540736514        spam   \n",
      "207    848089418049179651  derogatory   \n",
      "...                   ...         ...   \n",
      "54161  849807161718964225  derogatory   \n",
      "54163  848677547571335174        spam   \n",
      "54165  850292065174863873        spam   \n",
      "54186  850092932241686532        spam   \n",
      "54188  849523467372376064        spam   \n",
      "54191  847782558591045633        spam   \n",
      "54196  849674709763358720  derogatory   \n",
      "54197  849246676854484992  derogatory   \n",
      "54203  849040052881682432        spam   \n",
      "54213  850606126269960192        spam   \n",
      "54214  848137933580369921        spam   \n",
      "54216  847695895894163456        spam   \n",
      "54229  848569917527994370        spam   \n",
      "54233  848089816516493312        spam   \n",
      "54234  849380101863202819        spam   \n",
      "54236  849635522389651456  derogatory   \n",
      "54238  848346835076960256        spam   \n",
      "54239  849830066800517125        spam   \n",
      "54240  848986462259425281        spam   \n",
      "54242  850456293181538304  derogatory   \n",
      "54246  850308804663181312  derogatory   \n",
      "54249  848610052810387459        spam   \n",
      "54256  850270712011005952        spam   \n",
      "54258  848371250128924672        spam   \n",
      "54262  849080121072005121        spam   \n",
      "54273  847610298538131462        spam   \n",
      "54280  850562958505672709        spam   \n",
      "54285  850464673405251584        spam   \n",
      "54296  850003560012140548        spam   \n",
      "54302  848939985160077312        spam   \n",
      "\n",
      "                                                  tweets predicted_label  \n",
      "2      Damn dean just put Corbin to sleep. That Match...      derogatory  \n",
      "3      Dick Tracy Meets Gruesome - the 2017 re-boot\\n...          normal  \n",
      "15     @StephMcMahon looking like the bad ass bitch t...      derogatory  \n",
      "21     Alex Brosas another idiot #ALDUBKSGoesToUS  ht...      derogatory  \n",
      "23     \"THE FORCE AWAKENS: A Bad Lip Reading\" (Featur...      derogatory  \n",
      "34     @NikkisBubble Every bird turd is talking \"Chil...          normal  \n",
      "46     RT @nyctophil3: Pineapples do not belong on pi...      derogatory  \n",
      "75     Why Praise Can Be Bad for Kids - ABC News - ht...          normal  \n",
      "76     RT @THESLUMPGOD: I Sampled Jaws \\n\\nPull Up Wi...      derogatory  \n",
      "79     RT @Sixteen_digits: Police holds me. Anoda pol...      derogatory  \n",
      "83     Something is deeply wrong with him! That and t...          normal  \n",
      "93     He would not have won if the DNC knew what the...      derogatory  \n",
      "98     @roaringsoftly i will go to bat for you!!! wha...          normal  \n",
      "105    RT @siarah_: that's an ugly ass house to be pa...      derogatory  \n",
      "114    I'm baffled and disgusted, who raised these bi...          normal  \n",
      "121    Let it be known that I hate being a fucking te...      derogatory  \n",
      "124    @ProWLegacy @TennesseeHoney_ can you count its...      derogatory  \n",
      "128    RT @sobermongeau: you know when youre fucking ...      derogatory  \n",
      "141    @JesonthePage ugh, crippling self doubt is THE...          normal  \n",
      "142    RT @AndyRichter: Jesus, the Get Out sequel loo...      derogatory  \n",
      "143    @DibsOnTheGibbs At least outline the plot and ...          normal  \n",
      "153    Line from this #film \\n\"I don't take orders fr...          normal  \n",
      "174    @Record_Sport This will bite him on the arse s...          normal  \n",
      "180    Titanfall 2 - SALTBALL. GRAPPLE. RONIN. | Musi...          normal  \n",
      "181    RT @fromvallejo: son this nigga is the worst h...      derogatory  \n",
      "183    JAP Battle (EXPLICIT) - \"Crazy Ex-Girlfriend\" ...          normal  \n",
      "191    RT @DPRK_News: \"Attack dog\" US media meekly ko...      derogatory  \n",
      "193    . So sick of this #altmedia bullshit #fakenews...          normal  \n",
      "197    RT @BBErika_: Hate a nigga that try and run me...      derogatory  \n",
      "207    @pepsi No need to apologize because some peopl...          normal  \n",
      "...                                                  ...             ...  \n",
      "54161  @AirbnbHelp How long to you anticipate it taki...          normal  \n",
      "54163  @IamRustyCat @NancyCakeFace @luna_bell13 @TheL...          normal  \n",
      "54165  @JoRichardsKent @scotstanfield @Number10gov Oh...          normal  \n",
      "54186  I just voted for #TheUnassisted in the @Master...          normal  \n",
      "54188  Posted by : @ FastCompany #Business #Tech #Dig...          normal  \n",
      "54191  ‚úùAwakening The Human Brain To üíØ‚úùNo Fear Here‚úù\\...          normal  \n",
      "54196  Investors rein in their Trump-fueled optimism ...          normal  \n",
      "54197  People need to realise that if the person givi...          normal  \n",
      "54203  SOTT IS BEAUTIFUL \\nSOTT IS BEAUTIFUL\\nSOTT IS...          normal  \n",
      "54213  Download Wolf Hunger (SWAT) (EPUB &amp; PDF) P...          normal  \n",
      "54214  Not From The Onion: Pigeons To Get Birth Contr...          normal  \n",
      "54216  BarForage After Maize grass mixture looking ve...          normal  \n",
      "54229  Just another artsy book photo! What are you re...          normal  \n",
      "54233  ‚ùû‚Ä¢ 20 g WOOD BLEWIT #Spawn #Clitocybe Lepista ...          normal  \n",
      "54234  Funeral called off after ‚Äòdead man‚Äô was spotte...          normal  \n",
      "54236  If you dont have any #work to do, watch this i...          normal  \n",
      "54238  #CabinetReshuffle Thank @MYANC for destroying ...          normal  \n",
      "54239  Web Chef Kimberly Turner from https://t.co/t6n...          normal  \n",
      "54240  #Vintage #Devotions for #Adult Groups by Walla...          normal  \n",
      "54242  Hear @JessKupferman rave about her accidental ...          normal  \n",
      "54246  @TiwariLalmani @ParveenKader But People love t...            spam  \n",
      "54249  @Sensatus @holland_tom @TheScepticIsle But wid...          normal  \n",
      "54256  @ProjetoooHelp @onedirection @radiodisney @Nia...          normal  \n",
      "54258  @TheWalkingDead I don't know, but I would like...          normal  \n",
      "54262  It's your turn to Enter the Stars.\\n\\nWe are g...          normal  \n",
      "54273  @_DreadlocRasta Nah mayne .. wasnt close to me...          normal  \n",
      "54280  #Earths remnant arrives at distant #planet - c...          normal  \n",
      "54285  'Temple of the Bells' rushes to clip wings of ...          normal  \n",
      "54296  Ron Paul: 'Zero Chance' Assad Behind Syria Che...          normal  \n",
      "54302  Monitoring Your Social Media Mentions https://...          normal  \n",
      "\n",
      "[12115 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# let's see what happens when we retrain things on misclassified examples\n",
    "\n",
    "y_preds = model.predict(X)\n",
    "train['predicted_label'] = y_preds\n",
    "normal_examples = train[((train['maj_label']==\"spam\"))&(train['predicted_label']==\"spam\")]\n",
    "print(normal_examples)\n",
    "misclassified_examples = train[(train['maj_label']!=train['predicted_label'])]\n",
    "print(misclassified_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  derogatory       0.28      0.03      0.06       659\n",
      "      normal       0.84      0.61      0.70        76\n",
      "        spam       0.71      0.97      0.82      1688\n",
      "\n",
      "    accuracy                           0.70      2423\n",
      "   macro avg       0.61      0.54      0.53      2423\n",
      "weighted avg       0.60      0.70      0.61      2423\n",
      "\n",
      "accuracy: 0.702\n"
     ]
    }
   ],
   "source": [
    "X = list(misclassified_examples[\"tweets\"])\n",
    "y = list(misclassified_examples[\"maj_label\"])\n",
    "y_false = list(misclassified_examples[\"predicted_label\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "report = metrics.classification_report(y_test, y_preds)\n",
    "print(report)\n",
    "print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag: derogatory\n",
      "Most Positive Coefficients:\n",
      "[('stand', 1.0047159519820077), ('thank', 0.9793222323146172), ('without', 0.9648489503886257), ('american', 0.9189451173753155), ('coffee', 0.8697660132374775), ('rising', 0.8662864873397012), ('pleasure', 0.8536614824107929), ('2017', 0.8356997973590333), ('makes', 0.8251379520503926), ('get', 0.7859521885878996)]\n",
      "Most Negative Coefficients:\n",
      "[('rt', -3.895117470621849), ('fucking', -2.876284654404537), ('idiot', -2.49240419901193), ('ass', -1.6542050893435412), ('idiots', -1.2280074791300748), ('hate', -1.1618588277728645), ('bad', -0.9450558081252478), ('bitch', -0.9449889086660689), ('ugly', -0.902504784788593), ('stupid', -0.8229468351551408)]\n",
      "--------------------------------------\n",
      "Tag: normal\n",
      "Most Positive Coefficients:\n",
      "[('rt', 8.02871269458181), ('fucking', 6.21538492047141), ('idiot', 5.256941111927054), ('ass', 3.9007992192050778), ('bad', 2.8838996954492897), ('idiots', 2.812234781895666), ('hell', 2.704070663503978), ('hate', 2.6334117208287675), ('stupid', 2.468546641243352), ('fuck', 2.2398454461263246)]\n",
      "Most Negative Coefficients:\n",
      "[('co', -1.5669313150119408), ('https', -1.4928255782043474), ('in', -1.3503626768670454), ('more', -0.8885592924421261), ('for', -0.8258007500764525), ('to', -0.7455504502296819), ('at', -0.6909855898244219), ('will', -0.5828092899328025), ('good', -0.569247480755297), ('love', -0.5554220045497287)]\n",
      "--------------------------------------\n",
      "Tag: spam\n",
      "Most Positive Coefficients:\n",
      "[('great', 1.1823668506630973), ('in', 1.0109814363676428), ('co', 0.9271146413487172), ('new', 0.887671988826795), ('enough', 0.8870588789447987), ('seen', 0.812825843282448), ('https', 0.8082849245602346), ('service', 0.8078783672866087), ('getting', 0.8057114058183683), ('following', 0.8014122550725942)]\n",
      "Most Negative Coefficients:\n",
      "[('rt', -4.133595223959956), ('fucking', -3.339100266066871), ('idiot', -2.7645369129151076), ('hell', -2.504754723077531), ('fuck', -2.3429733792873244), ('ass', -2.246594129861533), ('damn', -2.055633236086387), ('bad', -1.9388438873240372), ('stupid', -1.6455998060882149), ('idiots', -1.584227302765587)]\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vec = model.steps[0][1]\n",
    "clf = model.steps[2][1]\n",
    "for i, tag in enumerate(clf.classes_):\n",
    "    coefficients = clf.coef_[i]\n",
    "    weights = list(zip(vec.get_feature_names(),coefficients))\n",
    "    print('Tag:',tag)\n",
    "    print('Most Positive Coefficients:')\n",
    "    print(sorted(weights,key=lambda x: -x[1])[:10])\n",
    "    print('Most Negative Coefficients:')\n",
    "    print(sorted(weights,key=lambda x: x[1])[:10])\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
